import os
import json
import base64
import io
from datetime import datetime
from typing import Dict, List, Any
from dotenv import load_dotenv
from openai import OpenAI
from pdf2image import convert_from_path

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(
    api_key=os.getenv('OPENAI_API_KEY'),
    base_url="https://api.openai.com/v1"
)

def convert_pdf_to_images(pdf_path: str) -> List[str]:
    """PDF íŒŒì¼ì„ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    
    Args:
        pdf_path: PDF íŒŒì¼ ê²½ë¡œ
        
    Returns:
        base64ë¡œ ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸
    """
    try:
        # PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
        images = convert_from_path(pdf_path)
        encoded_images = []
        
        for image in images:
            # ì´ë¯¸ì§€ë¥¼ JPEGë¡œ ë³€í™˜
            img_byte_arr = io.BytesIO()
            image.save(img_byte_arr, format='JPEG', quality=90)
            img_byte_arr = img_byte_arr.getvalue()
            
            # base64ë¡œ ì¸ì½”ë”©
            img_str = base64.b64encode(img_byte_arr).decode()
            encoded_images.append(img_str)
            
        return encoded_images
    except Exception as e:
        raise Exception(f"PDF ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

def load_segment_mapping(skip_segment_split: bool = True) -> Dict[str, Any]:
    """ì„¸ê·¸ë¨¼íŠ¸ ë§¤í•‘ ê²°ê³¼ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    if skip_segment_split:
        # ê°€ì¥ ìµœê·¼ì˜ ë§¤í•‘ ê²°ê³¼ íŒŒì¼ ì°¾ê¸°
        mapping_dir = "data/segment_mapping"
        if not os.path.exists(mapping_dir):
            raise FileNotFoundError(f"ë§¤í•‘ ê²°ê³¼ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {mapping_dir}")
        
        mapping_files = [f for f in os.listdir(mapping_dir) if f.startswith("segment_mapping_")]
        if not mapping_files:
            raise FileNotFoundError("ë§¤í•‘ ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        latest_file = max(mapping_files)
        path = os.path.join(mapping_dir, latest_file)
        
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    else:
        # ì‹¤ì œ ì„¸ê·¸ë¨¼íŠ¸ ë§¤í•‘ ì‹¤í–‰
        from segment_mapping import segment_mapping
        return segment_mapping()

def generate_summary(slide_image: str, merged_segments: str) -> Dict[str, Any]:
    """ë‹¨ì¼ ìŠ¬ë¼ì´ë“œì— ëŒ€í•œ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    prompt = f"""
You are an expert in creating structured notes based on long user inputs.

The user's input consists of:
- A **slide image** that shows the lecture content, and
- A set of **matching lecture segments** explaining details related to that slide.

Matched Lecture Segments:
\"\"\"
{merged_segments}
\"\"\"

# Important Writing Rules:

**ABSOLUTELY MUST** use the exact following titles, numbered exactly as shown:
   - "1. Concise Summary Notes"
   - "2. Bullet Point Notes"
   - "3. Keyword Notes"
   - "4. Chart/Table Summary"

1. **Concise Summary Notes**  
- Summarize the combined content into natural sentences within 7â€“8 lines.

2. **Bullet Point Notes**  
- List the key points clearly and briefly in bullet points.  
- Each point should be one sentence or a short phrase.

3. **Keyword Notes**  
- Extract and list around 10 major keywords, concepts, or important terms.  
- Provide a brief explanation for each keyword.

4. **Chart/Table Summary**  
- Try your best to summarize the content in a **chart or table format** if possible.
- A table is especially helpful when listing concepts, comparing items, or explaining step-by-step processes.  
- Only write "Omitted" if it is clearly impossible to express the content in a structured chart or table.

Important writing guidelines you must follow:
- Respond in English if the user input is in English; respond in Korean if the input is in Korean.
- Make the notes concise and clear so that users can understand quickly.
- Eliminate redundant expressions and maintain a logical flow.
- Clearly separate each style of note-taking in the output.
- If a style is not applicable, do not leave it blank; explicitly write Omitted.
- If there are no matching lecture segments for a slide, generate the notes based as much as possible on the slide image alone.
- Each style must be written only once. Do not repeat or duplicate the same style multiple times.

# Output Format Example:

1. ğŸ§ Concise Summary Notes
(Your concise summary here)

2. âœ…Bullet Point Notes
(Your bullet points here)
âˆ™ This is Bullet Point example
âˆ™ using This point "âˆ™"

3. ğŸ”‘Keyword Notes
(Your keywords here)
**Continuity** : Maintaining ongoing operations without disruption.  
**Independence** : Layers functioning without affecting each other.

4. ğŸ“ŠChart/Table Summary
(Your table here or "Omitted")

Now, generate the notes accordingly.
"""

    # ë””ë²„ê¹…ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ì¶œë ¥
    print("\n[DEBUG] ----- PROMPT BEGIN -----")
    print(f"[DEBUG] ë³‘í•©ëœ ì„¸ê·¸ë¨¼íŠ¸ ê¸¸ì´: {len(merged_segments)} ë¬¸ì")
    print("[DEBUG] ----- PROMPT END -----\n")

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "system",
                "content": "You are an expert in creating structured notes based on lecture content."
            },
            {
                "role": "user",
                "content": [
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{slide_image}",
                            "detail": "low"
                        }
                    },
                    {
                        "type": "text",
                        "text": prompt
                    }
                ]
            }
        ],
        functions=[
            {
                "name": "return_summary",
                "description": "Creates structured notes for a lecture slide.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "concise_summary": {
                            "type": "string",
                            "description": "Concise summary of the content"
                        },
                        "bullet_points": {
                            "type": "string",
                            "description": "Key points in bullet format"
                        },
                        "keywords": {
                            "type": "string",
                            "description": "Important keywords with explanations"
                        },
                        "chart_summary": {
                            "type": "object",
                            "properties": {
                                "ì£¼ì œ": {"type": "string"},
                                "ë¶€ì£¼ì œ": {"type": "string"}
                            },
                            "required": ["ì£¼ì œ", "ë¶€ì£¼ì œ"]
                        }
                    },
                    "required": ["concise_summary", "bullet_points", "keywords", "chart_summary"]
                }
            }
        ],
        function_call={"name": "return_summary"}
    )

    return json.loads(response.choices[0].message.function_call.arguments)

def create_summary(pdf_path: str = "assets/os_35.pdf", skip_segment_split: bool = True) -> Dict[str, Any]:
    """ëª¨ë“  ìŠ¬ë¼ì´ë“œì— ëŒ€í•œ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    # PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
    slide_images = convert_pdf_to_images(pdf_path)
    
    # ì„¸ê·¸ë¨¼íŠ¸ ë§¤í•‘ ë°ì´í„° ë¡œë“œ
    mapping_data = load_segment_mapping(skip_segment_split)

    # ê²°ê³¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬
    summaries = {}

    # ê° ìŠ¬ë¼ì´ë“œì— ëŒ€í•´ ìš”ì•½ ìƒì„±
    for slide_key, slide_data in mapping_data.items():
        if slide_key == "slide0":
            continue  # ë§¤í•‘ë˜ì§€ ì•Šì€ ì„¸ê·¸ë¨¼íŠ¸ëŠ” ìš”ì•½í•˜ì§€ ì•ŠìŒ
            
        slide_number = int(slide_key.replace("slide", ""))
        
        # ìŠ¬ë¼ì´ë“œ ë²ˆí˜¸ê°€ ì´ë¯¸ì§€ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ë©´ ê±´ë„ˆë›°ê¸°
        if slide_number > len(slide_images):
            continue

        # í•´ë‹¹ ìŠ¬ë¼ì´ë“œì˜ ì´ë¯¸ì§€
        slide_image = slide_images[slide_number - 1]

        # ì„¸ê·¸ë¨¼íŠ¸ í…ìŠ¤íŠ¸ ë³‘í•©
        segments = slide_data.get("Segments", {})
        merged_segments = "\n".join(
            f"Segment {seg_id}: {seg_data['text']}"
            for seg_id, seg_data in segments.items()
        )

        # ìš”ì•½ ìƒì„±
        summary = generate_summary(slide_image, merged_segments)
        
        # ê²°ê³¼ ì €ì¥
        summaries[slide_key] = {
            "Concise Summary Notes": summary["concise_summary"],
            "Bullet Point Notes": summary["bullet_points"],
            "Keyword Notes": summary["keywords"],
            "Chart/Table Summary": summary["chart_summary"]
        }

    # ê²°ê³¼ ì €ì¥
    output_dir = "data/summary"
    os.makedirs(output_dir, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M")
    output_path = os.path.join(output_dir, f"summary_{timestamp}.json")
    
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(summaries, f, ensure_ascii=False, indent=2)
    
    print(f"[INFO] ìš”ì•½ì´ {output_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤")
    
    return summaries

if __name__ == "__main__":
    create_summary(skip_segment_split=True) 