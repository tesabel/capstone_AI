import os
import json
import base64
import io
from datetime import datetime
from typing import Dict, List, Any
from dotenv import load_dotenv
from openai import OpenAI
from pdf2image import convert_from_path

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(
    api_key=os.getenv('OPENAI_API_KEY'),
    base_url="https://api.openai.com/v1"
)

def convert_pdf_to_images(pdf_path: str) -> List[str]:
    """PDF íŒŒì¼ì„ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    
    Args:
        pdf_path: PDF íŒŒì¼ ê²½ë¡œ
        
    Returns:
        base64ë¡œ ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸
    """
    try:
        # PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
        images = convert_from_path(pdf_path)
        encoded_images = []
        
        for image in images:
            # ì´ë¯¸ì§€ë¥¼ JPEGë¡œ ë³€í™˜
            img_byte_arr = io.BytesIO()
            image.save(img_byte_arr, format='JPEG', quality=90)
            img_byte_arr = img_byte_arr.getvalue()
            
            # base64ë¡œ ì¸ì½”ë”©
            img_str = base64.b64encode(img_byte_arr).decode()
            encoded_images.append(img_str)
            
        return encoded_images
    except Exception as e:
        raise Exception(f"PDF ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

def load_json_file(file_path: str) -> Dict[str, Any]:
    """JSON íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        raise Exception(f"JSON íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

def generate_summary(slide_data: Dict[str, Any], merged_segments: str) -> Dict[str, Any]:
    """ë‹¨ì¼ ìŠ¬ë¼ì´ë“œì— ëŒ€í•œ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    prompt = fprompt = f"""
### Slide Analysis
Type: {slide_data['type']}
Title Keywords: {', '.join(slide_data['title_keywords'])}
Secondary Keywords: {', '.join(slide_data['secondary_keywords'])}
Detail: {slide_data['detail']}

### Matched Lecture Segments
{merged_segments}

## Writing Guidelines  â”€â”€ FOLLOW EXACTLY
1. concise_summary  
   â€¢ 7â€“8 short sentences.  
   â€¢ **Bold** each core keyword once. 

2. bullet_points  
   â€¢ Use the "âˆ™" bullet symbol.  
   â€¢ One sentence or phrase per bullet.  
   â€¢ End each bullet entry with (\n).

3. keywords  
   â€¢ About 10 entries in the form **Keyword** â€“ (explanation).  
   â€¢ End each keyword entry with (\n).

4. chart_summary  
   â€¢ Provide a table / step list if meaningful; otherwise write "Omitted".  


## Example
concise_summary
Operating systems manage **resources**, provide **abstraction**, and ensure **security**. They coordinate **processes** and **threads**, ...
bullet_points  
âˆ™ Manages CPU, memory, and I/O devices
âˆ™ Provides process & thread abstraction
âˆ™  ...


keywords  
**Process** â€“ (An executing program instance)
**Thread** â€“ (Lightweight unit of CPU scheduling)
...

chart_summary  
| Component | Role |  
|-----------|-------------------------------|  
| CPU       | Executes instructions         |  
| Memory    | Stores code & data            |  
...

General rules (**FOLLOW EXACTLY**)
- Write in Korean. 
- If a part is impossible, output "Omitted" for that part.
"""

    # ë””ë²„ê¹…ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ì¶œë ¥
    print("\n[DEBUG] ----- PROMPT BEGIN -----")
    print(f"[DEBUG] ë³‘í•©ëœ ì„¸ê·¸ë¨¼íŠ¸ ê¸¸ì´: {len(merged_segments)} ë¬¸ì")
    print("[DEBUG] ----- PROMPT END -----\n")

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "system",
                "content": "You are an expert in creating structured notes based on lecture content."
            },
            {
                "role": "user",
                "content": prompt
            }
        ],
        functions=[
            {
                "name": "return_summary",
                "description": "Creates structured notes for a lecture slide.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "concise_summary": {
                            "type": "string",
                            "description": "Concise summary of the content"
                        },
                        "bullet_points": {
                            "type": "string",
                            "description": "Key points in bullet format"
                        },
                        "keywords": {
                            "type": "string",
                            "description": "Important keywords with explanations"
                        },
                        "chart_summary": {
                            "type": "object",
                            "properties": {
                                "ì£¼ì œ": {"type": "string"},
                                "ë¶€ì£¼ì œ": {"type": "string"}
                            },
                            "required": ["ì£¼ì œ", "ë¶€ì£¼ì œ"]
                        }
                    },
                    "required": ["concise_summary", "bullet_points", "keywords", "chart_summary"]
                }
            }
        ],
        function_call={"name": "return_summary"}
    )

    return json.loads(response.choices[0].message.function_call.arguments)

def create_summary(
    image_captioning_data: Dict[str, Any],
    segment_mapping_data: Dict[str, Any],
    progress_callback=None
) -> Dict[str, Any]:
    """ëª¨ë“  ìŠ¬ë¼ì´ë“œì— ëŒ€í•œ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        image_captioning_data: ì´ë¯¸ì§€ ìº¡ì…”ë‹ ê²°ê³¼ JSON ë°ì´í„°
        segment_mapping_data: ì„¸ê·¸ë¨¼íŠ¸ ë§¤í•‘ ê²°ê³¼ JSON ë°ì´í„°
        progress_callback: ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ ì½œë°± í•¨ìˆ˜
        
    Returns:
        ìƒì„±ëœ ìš”ì•½ ë°ì´í„°
    """
    # ê²°ê³¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬
    summaries = {}

    # ì²˜ë¦¬í•  ìŠ¬ë¼ì´ë“œ ëª©ë¡ ìƒì„±
    slides_to_process = []
    for slide_key in segment_mapping_data.keys():
        if slide_key == "slide0":
            continue
            
        slide_number = int(slide_key.replace("slide", ""))
        if slide_number > len(image_captioning_data):
            continue
            
        slides_to_process.append((slide_key, slide_number))

    total_slides = len(slides_to_process)
    
    # ê° ìŠ¬ë¼ì´ë“œì— ëŒ€í•´ ìš”ì•½ ìƒì„±
    for i, (slide_key, slide_number) in enumerate(slides_to_process, 1):
        # ì§„í–‰ë¥  ì½œë°± í˜¸ì¶œ
        if progress_callback:
            progress_callback(i, total_slides)
            
        # í•´ë‹¹ ìŠ¬ë¼ì´ë“œì˜ ìº¡ì…”ë‹ ë°ì´í„°
        slide_caption = image_captioning_data[slide_number - 1]

        # ì„¸ê·¸ë¨¼íŠ¸ í…ìŠ¤íŠ¸ ë³‘í•©
        segments = segment_mapping_data[slide_key].get("Segments", {})
        merged_segments = "\n".join(
            f"Segment {seg_id}: {seg_data['text']}"
            for seg_id, seg_data in segments.items()
        )

        # ìš”ì•½ ìƒì„±
        summary = generate_summary(slide_caption, merged_segments)
        
        # ê²°ê³¼ ì €ì¥
        summaries[slide_key] = {
            "Concise Summary Notes": f"ğŸ§ Concise Summary Notes\n{summary['concise_summary']}",
            "Bullet Point Notes": f"âœ…Bullet Point Notes\n{summary['bullet_points']}",
            "Keyword Notes": f"ğŸ”‘Keyword Notes\n{summary['keywords']}",
            "Chart/Table Summary": f"ğŸ“ŠChart/Table Summary\n{summary['chart_summary']}"
        }

    # ê²°ê³¼ ì €ì¥
    output_dir = "data/summary"
    os.makedirs(output_dir, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M")
    output_path = os.path.join(output_dir, f"summary_{timestamp}.json")
    
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(summaries, f, ensure_ascii=False, indent=2)
    
    print(f"[INFO] ìš”ì•½ì´ {output_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤")
    
    return summaries

if __name__ == "__main__":
    import sys
    
    try:
        # ê°€ì¥ ìµœê·¼ ì´ë¯¸ì§€ ìº¡ì…”ë‹ ê²°ê³¼ íŒŒì¼ ì°¾ê¸°
        captioning_dir = "data/image_captioning"
        captioning_files = [f for f in os.listdir(captioning_dir) if f.startswith("image_captioning")]
        if captioning_files:
            latest_captioning = max(captioning_files)
            with open(os.path.join(captioning_dir, latest_captioning), 'r', encoding='utf-8') as f:
                image_captioning_data = json.load(f)
        else:
            raise Exception("ì´ë¯¸ì§€ ìº¡ì…”ë‹ ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
        # ê°€ì¥ ìµœê·¼ ì„¸ê·¸ë¨¼íŠ¸ ë§¤í•‘ ê²°ê³¼ íŒŒì¼ ì°¾ê¸°
        mapping_dir = "data/segment_mapping"
        mapping_files = [f for f in os.listdir(mapping_dir) if f.startswith("segment_mapping")]
        if mapping_files:
            latest_mapping = max(mapping_files)
            with open(os.path.join(mapping_dir, latest_mapping), 'r', encoding='utf-8') as f:
                segment_mapping_data = json.load(f)
        else:
            raise Exception("ì„¸ê·¸ë¨¼íŠ¸ ë§¤í•‘ ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # JSON ë°ì´í„°ë¥¼ ì§ì ‘ ì „ë‹¬
        results = create_summary(
            image_captioning_data=image_captioning_data,
            segment_mapping_data=segment_mapping_data
        )
        print(json.dumps(results, indent=2, ensure_ascii=False))
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        sys.exit(1)